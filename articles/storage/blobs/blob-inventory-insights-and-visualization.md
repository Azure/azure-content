---
title: Insights from Azure Storage blob inventory and visualization
description: Visualize and get insights from data access patterns using Azure Storage inventory
services: storage
author: shubhamja

ms.author: shubhamja
ms.date: 08/24/2022
ms.service: storage
ms.subservice: blobs
ms.tops: how-to
---

# Insights from Azure Storage blob inventory and visualization

The [Azure Storage blob inventory](/azure/storage/blobs/blob-inventory) feature provides an overview of your containers, blobs, snapshots and blob versions within a storage account. The inventory report can be used to understand various attributes of blobs and containers such as total data size, age, encryption status, immutability policy, legal hold and so on.

Running inventory generates raw data and we have to process the data to generate insights on top of it. This article explains how the Azure Blob Storage Inventory, Azure Synapse and PowerBI can be used to generate insights and visualize them. This will also be helpful in optimizing the use of storage accounts.

## List of insights

1. Overview
    1. Overall growth in data
    1. Amount of data created over time
    1. Modification in data
    1. Snapshot size over time
1. Detailed analysis
    1. Data access pattern in Hot and Cool tier
    1. Distribution of data across tier
    1. Distribution of data across blob types
1. Breakdown of reports
    1. Distribution of blob in blob types
    1. Distribution of data in containers
    1. Distribution of blobs in access tiers
    1. Distribution of data in file types

## Sample visualizations

:::image type="content" source="media/blob-inventory-insights-and-visualization/power-bi-report-overview.png" alt-text="PowerBI report overview":::

:::image type="content" source="media/blob-inventory-insights-and-visualization/power-bi-report-detailed-analysis.png" alt-text="PowerBI report detailed analysis":::

:::image type="content" source="media/blob-inventory-insights-and-visualization/power-bi-report-breakdown.png" alt-text="PowerBI report breakdown":::

## Limitations

The code samples provided in this article are only helpful for blob inventory rules created for Blob object types.

## Steps for generating insights and visualizations

### Enable inventory reports

The first step in this method is to [enable inventory reports](/azure/storage/blobs/blob-inventory-how-to?tabs=azure-portal) on your storage account. You may have to wait up to 24 hours after enabling inventory reports for your first report to be generated.

### Create resources

#### Manually

**Create an Azure Synapse workspace**

[Create an Azure Synapse workspace](/azure/synapse-analytics/get-started-create-workspace) where you will execute a PySpark notebook to generate the report for inventory results.

Do remember to grant **Storage Blob Data Contributor** access to Synapse workspace's Managed Service Identity(MSI).

**Create Apache Spark pool in Synapse workspace**

Next step is to [create a Apache Spark pool](azure/synapse-analytics/get-started-analyze-spark) in the Synapse workspace created above. This Apache Spark pool will be used to execute PySpark notebook that will process the reports generated by Azure Blob Storage Inventory.

#### Create resource (via ARM template)

Deploy [SynapseArmTemplate.json](./src/arm-templates/SynapseArmTemplate.json) from Azure portal using [Deploy a custom template](azure/azure-resource-manager/templates/quickstart-create-templates-use-the-portal) service.

### Configure permissions

Grant yourself and other users who will require access to data visualization following roles:

1. [Storage Blob Data Contributor role on Storage account used while creating the Synapse workspace](azure/synapse-analytics/get-started-add-admin#azure-rbac-role-assignments-on-the-workspaces-primary-storage-account).

1. [Contributor role on Synapse workspace](azure/synapse-analytics/get-started-add-admin#azure-rbac-owner-role-for-the-workspace).

1. [Synapse Administrator role on Synapse studio](azure/synapse-analytics/get-started-add-admin#synapse-rbac-synapse-administrator-role-for-the-workspace).

Please note that this step needs to be repeated for each user that will run the PySpark notebook used later in this documentation and also for users who will visualize the data using PowerBI.

### Update and upload configuration file

Download [BlobInventoryStorageAccountConfiguration.json](./src/BlobInventoryStorageAccountConfiguration.json) and update the placeholders inside it in following manner:

1. *storageAccountName*: Name of storage account where inventory reports are stored

1. *destinationContainer*: Name of container inside storage account where inventory reports are stored

1. *blobInventoryRuleName*: Name of the inventory rule whose results should be analyzed

1. *accessKey*: [Access keys for the storage account](azure/storage/common/storage-account-keys-manage?tabs=azure-portal#view-account-access-keys) where inventory reports are stored

After updating the above placeholders, upload the configuration file in the storage container used while creating Synapse workspace.

### Import PySpark notebook

After you create the above resources and assign the permissions, do the following steps:

1. Download [ReportAnalysis.ipynb](./src/ReportAnalysis.ipynb).

1. Navigate to [https://web.azuresynapse.net](https://web.azuresynapse.net).

1. Select the **Develop** tab on the left edge.

1. Select the large plus sign (+) to add an item.

1. Select Import.

1. This will open a select file dialog. Upload the [ReportAnalysis.ipynb](./src/ReportAnalysis.ipynb) downloaded above.

    :::image type="content" source="media/blob-inventory-insights-and-visualization/synapse-studio-import-dialog.png" alt-text="Select Import to import PySpark notebook":::

1. This will also open a Properties tab on the right. Select **Configure Session**.

    :::image type="content" source="media/blob-inventory-insights-and-visualization/pyspark-notebook-configure-session.png" alt-text="Select Configure Session to configure spark pool":::

1. Select the Apache Spark pool created earlier in the **Attach to** dropdown and click **Apply**

1. In the first cell of Python notebook, update the value of **storage_account** and **container_name** variables to name of storage account and containers which were used while creating the synapse workspace respectively.

### Running the PySpark notebook

1. In the PySpark notebook imported above, click on **Run all**

1. It will take 3-4 minutes to start the spark session and another couple of minutes to process the existing reports.

Please note that the first time run can take longer than usual time since it will need to process all the existing reports. Subsequent runs will only process incremental data.

### Visualizing the data

Open [ReportAnalysis.pbit](./src/ReportAnalysis.pbit) file using [PowerBI desktop application](https://powerbi.microsoft.com/desktop/). Please note that this file does not render properly with PowerBI web application. In the report, a popup will open similar to one shown below. In this popup, enter name of the synapse workspace in **synapse_workspace_name** and **database_name** as **reportdata**.

:::image type="content" source="media/blob-inventory-insights-and-visualization/power-bi-report-popup.png" alt-text="Enter name of synapse workspace in synapse_workspace_name and report_data in database_name":::

If you see any error/warning in opening the PowerBI report, including but not limited to:

1. The key didnâ€™t match any row in the table

1. Access to the resource is forbidden

Please make sure the user logged into PowerBI has the required access mentioned in [Configure permissions](#configure-permissions) step.

## Next steps

- [Use Azure Storage blob inventory to manage blob data](azure/storage/blobs/blob-inventory)
- [Optimize costs by automatically managing the data lifecycle](azure/storage/blobs/lifecycle-management-overview)
- [Create scheduled data trigger to automatically process inventory reports](azure/data-factory/how-to-create-schedule-trigger?tabs=data-factory)
